# Data Notes

## Current Data Status

### Synthetic Data (Current)
The project currently uses **synthetic data** for testing and development:
- Generated by `data/generate_sample_data.py`
- Allows testing without real dataset dependencies
- Suitable for scaling and performance experiments

### Real METR-LA Data (Future)
- Scripts prepared: `data/fetch_data.sh` and `data/preprocess_metr_la.py`
- Not yet integrated/tested
- Will be used for final validation and paper results

## Results Data

### Scaling Results
- `results/scaling/strong_scaling_analysis.csv` - **Sample/Generated data** for demonstration
- `results/scaling/weak_scaling_analysis.csv` - **Sample/Generated data** for demonstration
- These are generated by `scripts/generate_sample_results.py` for documentation purposes
- **Real scaling results** will be generated when multi-node experiments complete successfully

### Profiling Results
- `results/profiling/metrics.csv` - Contains real profiling data from single-node runs
- `results/profiling/gpu_monitor.csv` - Real GPU monitoring data
- `results/profiling/cpu_monitor.csv` - Real CPU monitoring data

### Training Results
- `results/baseline_4104/` - **Real training results** from single-node baseline
- `results/ddp_*/` - Multi-node attempts (some failed, need cluster testing)

## Distinguishing Real vs Sample Data

**Real Data:**
- Training checkpoints (`.pth` files)
- Metrics from actual job runs (`.out`, `.err` files with job IDs)
- Profiling CSV files from monitoring tools

**Sample/Generated Data:**
- Scaling analysis CSVs (until real experiments complete)
- Any data explicitly generated by `generate_sample_results.py`

## Next Steps

1. Complete successful multi-node DDP runs
2. Generate real scaling analysis from actual runs
3. Update README with real results
4. Integrate real METR-LA dataset for final validation
